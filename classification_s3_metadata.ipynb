{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classifying S3 Data Sensitivity with Machine Learning\n",
    "This notebook demonstrates how to categorize S3 data objects as sensitive or non-sensitive by analyzing object metadata with Python and scikit-learn.\n",
    "\n",
    "## 1. Business Problem\n",
    "With data stored in S3 buckets, we need an automated way to identify sensitive data and enforce security policies. Manually classifying data does not scale.\n",
    "\n",
    "We will build a proof of concept to show how object metadata like bucket names and access patterns can be used to train an ML model to classify sensitivity.\n",
    "\n",
    "## 2. Sample Data\n",
    "We create sample metadata for a few S3 objects containing attributes like bucket name and last accessed date:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0b2304e3b7dcb92"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         s3bucket  days_since_access\n",
      "0  financial-data               2291\n",
      "1      model-data                119\n",
      "2       log-files               2733\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [{'s3bucket': 'financial-data', 'days_since_access': 2291},\n",
    "        {'s3bucket': 'model-data', 'days_since_access': 119},\n",
    "        {'s3bucket': 'log-files', 'days_since_access': 2733}]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T21:18:58.207244Z",
     "start_time": "2024-01-20T21:18:58.201191Z"
    }
   },
   "id": "72779e47d1bd80bc",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Feature Engineering\n",
    "We transform the text data about S3 bucket names into numeric vectors using scikit-learn's TfidfVectorizer. This encoder converts text into tf-idf vectors.\n",
    "\n",
    "TfidfVectorizer removes stopwords, applies tokenization, ngram generation, and calculates document frequencies to encode text data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba40e4742cd269fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['s3bucket'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T21:18:59.740472Z",
     "start_time": "2024-01-20T21:18:59.730920Z"
    }
   },
   "id": "2b125f957fde54cf",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Classification Model\n",
    "With numeric vectors representing the data, we can train a classification algorithm to predict sensitivity labels:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dc7c842b0b60c58"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "MultinomialNB()",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "y = [0, 1, 0] # Labels - 0 = non-sensitive, 1 = sensitive\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X, y) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T21:19:01.431801Z",
     "start_time": "2024-01-20T21:19:01.408700Z"
    }
   },
   "id": "43396f647f7b915a",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Making Predictions\n",
    "We can now use our model to classify new S3 objects:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e30f9cfc09fffc0c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(['financial-reports'])\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "print(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T21:19:02.625817Z",
     "start_time": "2024-01-20T21:19:02.614770Z"
    }
   },
   "id": "f2c14d1e26c2bc14",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Evaluating Performance\n",
    "We check accuracy on sample data by comparing to known labels:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82f0615b07e47e2f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.6666666666666666"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = np.array([0, 1, 0])\n",
    "y_pred = np.array([0, 1, 1])\n",
    "\n",
    "accuracy_score(y, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T21:19:03.962712Z",
     "start_time": "2024-01-20T21:19:03.957292Z"
    }
   },
   "id": "f9473cac3137ecfc",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "In real applications, precision and recall also matter for sensitive data.\n",
    "\n",
    "This notebooks shows a basic workflow for metadata-based S3 classification with Python. Next steps could include larger data, better features, and tuning models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "597624ad3a0beaac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "68e6ee21345fd896"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
